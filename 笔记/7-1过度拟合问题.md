# 过拟合问题

拟合的结果有三种
- 欠拟合、高偏差  假设函数中的项数不足
- 刚刚好
- 过拟合、高方差？  假设函数中的项数太多

过拟合表现为可以完全拟合样本中的数据，甚至可以使代价函数为0，但是在面对新的数据使不能有很好的表现，“无法泛化到新样本中”

三种结果可以在线性回归模型和logistic回归中体现。



## 导致过拟合的原因
在面对问题时，如果参数少，我们可以绘图，手动选择假设函数的多项式。

但是当参数变多时，绘图变得困难，难以手动选择假设函数的多项式。

当参数多，样本少的时候，就会出现过拟合问题，即选择了不适合的多项式

## 如何识别过拟合

如何识别过拟合有专门的工具，之后会讲

## 过拟合的解决办法
1. 减少参数的数量
   - 手动筛选参数，只保留部分参数
   - 使用模型选择算法，自动选择保留那些参数
   - 缺点：可能所有变量对于预测都是有用的，舍弃变量相当于舍弃信息
2. 正则化
   - 保留所有变量，但是减少其量级、或θ_j的大小
   - 在我们有许多参数，但是每个参数都对预测y的值有影响的时候

# 正则化

## 举例说明思想
见pdf第一页  
假设θ1~3都是正常的，θ3和4是过拟合的  
我们可以在代价函数里为θ3和4添加两项“惩罚项”，使得在这两项过大时，代价函数会变得很大。  
此时再去优化代价函数，会使得θ3和4近乎为0，使拟合出来的曲线相对平滑，减少过拟合。

但是实际中，我们并不知道哪些参数使会导致过拟合的，于是我们在代价函数中为所有参数添加一项。

## 正则化的代价函数
- 旧的代价函数    
J(θ_0,θ_1)=∑{i=1~m}[h_θ(x_i)-y_i]²/2m
- 正则化的代价函数  
J(θ_0,θ_1)={∑{i=1~m}[h_θ(x_i)-y_i]²+λ*∑{j=1~n}[θ_j²]}/2m

一般不会对θ_0设置惩罚项

此时代价函数包括了两个目标，一个是使假设函数尽量贴紧样本，另一个就是使假设函数尽量平滑。

其中的λ为正则化参数，代表惩罚力度，用于平衡这两个目标。

如果λ设的太大会导致欠拟合。  
比如在现行回归模型中最后只会剩下一个θ_0，其他项都接近0了，也不能很好的进行拟合的预测。  
因此应该选择一个合适的λ

# 线性回归的正则化
代价函数见pdf第一页

## 梯度下降法

对θ_0单独求偏导项
剩下的求通式

与之前的相比，一开始的θ_j项变为θ_j*(1-α*λ/m)  
其中α很小，m很大，所以约等于θ_j*0.99，也就是θ_j自己缩小了一点

## 正则方程法
θ=(X'X+λ*A)X'y  
其中矩阵A为n+1阶单位矩阵把第一个1变为0的矩阵。

之前有括号中的项是否会不可逆的问题，但是加了一项后，就必然可逆了

# 逻辑回归的正则化
分为梯度下降算法和

## 梯度下降算法
把惩罚项加上之后，按照之前的逻辑取计算偏导项，进行迭代

## 高级算法
把惩罚项加上之后，按照之前的格式去补充costFunction

其中θ_0和其他还是要分开
